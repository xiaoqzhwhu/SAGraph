#coding=utf-8
import sys
import openai
import time
import json
import random
import os
from retrying import retry
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import joblib
from evaluate import ranking_evaluation
import itertools
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
import numpy as np

product = "huohuasiwei"
product = "brush"
# product = "yunjing"
# product = "cream"
# product = "abc"
# product = "alice"
# product = "suboer"
relation_file = "t100/%s_r5_relation.txt" % product
static_file = "t100/%s_r5.static.graph" % product
dynamic_file = "t100/%s_r5.dynamic.graph" % product
feature_file = "t100/%s.feature.v6" % product
PRODUCT_DETAIL = {
    "huohuasiwei": {
        "product_name": "ç«èŠ±æ€ç»´", 
        "product_type": "æ•™è‚²", 
        "product_info": "ç«èŠ±æ€ç»´11æœˆæ´»åŠ¨æµ·æŠ¥è§å›¾ï¼4880å…ƒåˆ°æ‰‹48èŠ‚è¯¾ï¼Œèµ é€1W5ç«èŠ±å¸ï¼Œå¬åŠ›ç†Šå¬åŠ›æœºï¼Œç§‘æ™®ä¹¦ã€Šä¸–ç•ŒçœŸå¥‡å¦™ã€‹10å¥—ã€‚é•¿æŒ‰æ‰«ç å³å¯è´­ä¹°ï½\né€äº†å‡ ä¸ªæœˆçš„ç‰ç±³ï¼Œè¿™æ¬¡æ¢èµ å“äº†ï¼Œ\nprå§”å©‰çš„æé†’æˆ‘ï¼š\nä½ æ€»é€ç‰ç±³ï¼Œå¤§å®¶ä¼šä¸ä¼šåƒå¤Ÿäº†å‘¢[å¹¶ä¸ç®€å•][å¹¶ä¸ç®€å•]\nè¿™æ¬¡æ¢æˆä¸€å¥—ç§‘æ™®ä¹¦å•¦ï¼\n11æœˆä¹°è¯¾çš„éƒ½ä¼šå‘è¿™å¥—ä¹¦å—·ï¼\nå¦‚æœæœ‰æƒ³è¦ç‰ç±³çš„ï¼Œ\nä¹Ÿå¯ä»¥å•ç‹¬ç§ä¿¡æˆ‘æ¢ç¤¼å“",
        "gt_ids": ["1748332981", "1674427277", "3213060995", "1929045072"]
        },
    "brush": {
        "product_name": "å¾•èŠ¬æ‰«æŒ¯ç”µåŠ¨ç‰™åˆ·",
        "product_type": "æ•°ç ",
        "product_info": "ä¹‹å‰è®©é«˜é€Ÿå¹é£æœºæ›´åŠ æ™®åŠçš„#å¾•èŠ¬#ï¼Œè¿™æ¬¡åˆæ¥æ™®åŠç”µåŠ¨ç‰™åˆ·äº†ï¼Œâ€œæœå‘³â€å®è¶³çš„å¤–è§‚ï¼Œæ‰«æŒ¯ä¸€ä½“çš„è®¾è®¡é…ä¸Šå¾•èŠ¬è‡ªç ”ä¼ºæœç³»ç»Ÿï¼Œä¸å¾—ä¸è¯´å¾•èŠ¬çš„ç”µåŠ¨ç‰™åˆ·åœ¨æ¸…æ´èƒ½åŠ›ä¸Šç¡®å®æœ‰ä¸¤æŠŠåˆ·å­ã€‚",
        "gt_ids": ["1738877650", "1960732503", "1363450462", "1669537002", "3309403941"]
        },
    "cream": {
        "product_name": "çº¢å®çŸ³é¢éœœ",
        "product_type": "ç¾å¦†",
        "product_info": "çº¢å®çŸ³é¢éœœæ˜¯æˆ‘è¿‘å‡ å¹´ç”¨æœ€å¤šçš„é¢éœœï¼Œè¶…çº§çˆ±ç”¨ã€‚å‡çº§åä½¿ç”¨æ„Ÿæ›´å¥½äº†ï¼Œç”¨äº†ä¹‹åæ„Ÿè§‰çš®è‚¤çŠ¶æ€ä¹Ÿå¾ˆå¥½ã€‚ä¹Ÿå‡ ä¹å¹´å¹´éƒ½è·Ÿç€è±é›…åˆä½œï¼Œä»Šå¹´æˆ‘ä¹Ÿä»¥ä¸ºåˆä½œäº†ï¼Œç»“æœä¸€é—®æ‰å‘ç°æ²¡æœ‰[ç ´æ¶•ä¸ºç¬‘]æé”™äº†ï¼Œå¤§å®¶å¯ä»¥æœæœçœ‹åˆ«çš„åšä¸»æœ‰æ²¡æœ‰åˆä½œçš„ï¼ŒçœŸçš„å¥½å¥½ç”¨ã€‚é¢è†œä¹Ÿå¥½ç”¨ï¼Œæœ‰ç²¾åæ‰“åº•ï¼Œä¼šè§‰å¾—æ•ˆæœä¸æ˜¯è¡¨é¢çš„ï¼Œæˆ‘æ™šä¸ŠæŠ¤è‚¤ç¯èŠ‚éƒ½æ˜¯é¢è†œ+é¢éœœï¼Œå°±è§‰å¾—æ»‹æ¶¦å¾ˆæ·±å…¥ï¼Œè„¸è½¯è½¯å˜­å˜­çš„ã€‚ ",
        "gt_ids": ["2786726492", "2803674644", "2833050332", "1776459797", "3993044286", "2360171883", "1832452643"]
        },
    "yunjing": {
        "product_name": "äº‘é²¸æ™ºèƒ½æ´—åœ°æœº",
        "product_type": "å®¶å±…",
        "product_info": "æˆ‘å‘æ¥éƒ½æ˜¯èƒ½ä¸ç”¨æ‰‹ï¼Œå°±ä¸åŠ¨è…¿ï¼Œæ‹–åœ°è¿™ç§æ˜¯ï¼Œäº¤ç»™æ‰«æ‹–æœºå™¨äººä¸å°±å¥½äº†ï¼Œç›´åˆ°æˆ‘ç”¨ä¸Šäº†æœ€æ–°å‘å¸ƒçš„äº‘é²¸æ™ºèƒ½æ´—åœ°æœºS1ï¼Œä¸ä»…è½»ä¾¿ï¼Œè¿˜æ´—çš„å¹²å‡€ï¼Œæœ‹å‹ä»¬ï¼Œæˆ‘å±…ç„¶çˆ±ä¸Šæ´—åœ°äº†ï¼æ¥çœ‹çœ‹ï¼",
        "gt_ids": ["2292724833", "1642720480", "1735618597", "3340909732"]
        },
    "abc": {
        "product_name": "ABCReading",
        "product_type": "æ•™è‚²",
        "product_info": "ã€ABCreadingç›´æ’­ç¦åˆ©ä¸“åœºã€‘\nğŸ”¥SVIP 3å¹´å¡ç‹¬å®¶æ´»åŠ¨ï¼Œåˆ°æ‰‹4å¹´ï¼\nğŸ†åˆ†çº§é˜…è¯»TOP1ï¼Œ è¶…è¿‡3000ä¸‡ä¸­å›½å­©å­éƒ½åœ¨ç”¨çš„APP\nğŸŒŸæµ·æ·€å››å¤§é¸¡å¨ƒç¥å™¨ï¼Œåˆ†æ€§ç¿çº§é˜…è¯»ç™¾ç§‘å…¨ä¹¦ï¼Œå­¦è‹±è¯­å¿…å¤‡",
        "gt_ids": ["1689918212", "1468736221", "2626683933", "6690736938"]
        },
    "alice": {
        "product_name": "çˆ±ä¸½ä¸ç”µå‹åŠ›é”…",
        "product_type": "å®¶å±…",
        "product_info": "ä¸€ä¸ªé«˜é¢œå€¼çš„å¤šåŠŸèƒ½çš„é”…ï¼Œå¯ä»¥ç”¨æ¥ç…®é¥­ã€ç…®ç²¥ã€ç‚–çº¢çƒ§è‚‰ã€ç‚–è¹„ç­‹ã€ç‚–æ’éª¨æ±¤ç­‰ã€‚æ®è¯´è¿˜å¯ä»¥åšä½æ¸©æ–™ç†ï½ æˆ‘ç›®å‰è¯•è¿‡ç‚–æ’éª¨æ±¤ï¼ˆæ’éª¨ç‰ç±³ï¼Œæ’éª¨èåœï¼‰ï¼Œè‚‰å¯ä»¥ç‚–çš„å¾ˆçƒ‚ï¼Œå…¥å£å³åŒ–ï¼ç‚–çƒ‚çš„è‚‰æ­é…å°é©¬å“¥çš„â€œç¥–ä¼ ç§˜åˆ¶â€æ²¾æ°´ï¼Œå¤ªå¥½åƒäº†ï¼ç‚–ç…®çš„æ—¶å€™å¤§éƒ¨åˆ†å®ƒéƒ½å¾ˆå®‰é™ï¼Œä¸ä¼šåƒä¼ ç»Ÿæ”¾æ˜ç«ä¸Šçš„è€å¼é«˜å‹é”…æœ‰å£°éŸ³ã€‚",
        "gt_ids": ["5426716682", "5716589670", "1806558670", "2503628005"]
        },
    "suboer": {
        "product_name": "è‹æ³Šå°”å¢å‹è¿‡æ»¤èŠ±æ´’",
        "product_type": "å®¶ç”µ",
        "product_info": "ã€99rmbçš„è‹æ³Šå°”å‡€æ°´å¢å‹èŠ±æ´’æ¥å•¦ï½åˆ°æ‰‹ä¸‰ç®¡æ»¤èŠ¯ã€‘èƒ½å¤Ÿè¿‡æ»¤æ‰è‡ªæ¥æ°´ä¸­â€œæ°¯å…ƒç´ /æ°´é”ˆç­‰æœ‰å®³ç‰©è´¨â€ã€‚æˆ‘å¯¹æ°´è´¨çš„è¦æ±‚å¾ˆé«˜ï¼Œå¾ˆæ—©å°±å¼ºè°ƒè¿‡çš®è‚¤â•å¤´å‘å¥½çš„ä¸€å¤§å½±å“å› ç´ å°±æ˜¯æ°´è´¨ã€‚æˆ‘ç”¨æ™®é€šèŠ±æ´’æ´—æ¾¡çš„è¯å‘å°¾åå¹²æ¶©ï¼Œæ¢å‡€æ°´èŠ±æ´’åå¤´å‘æ´—å®Œå°±éå¸¸é¡ºæ»‘äº†ã€‚å¦‚æœä½ ä»¬è‚Œè‚¤æ•æ„Ÿå¹²ç‡¥ï¼Œå®¹æ˜“é•¿ç—˜èµ·çš®ï¼Œå¤´å‘å¹²æ¶©ï¼Œè„±å‘åˆæ¯”è¾ƒä¸¥é‡å¯ä»¥å…ˆè¯•è¯•å»è¿‡æ»¤æ‰æ—¥å¸¸ç”¨æ°´ä¸­çš„æœ‰å®³ç‰©è´¨ã€‚",
        "gt_ids": ["3051159885", "1506441127", "6883393827", "5831203045"]
    }
    }
PROMPT_DICT = {
    "prompt4staticprofile": "æ¯ä¸ªæ ‡å·åé¢æ˜¯ç”¨æˆ·çš„ä¸ªæ€§ç­¾åï¼Œè¯·ä»¥jsonåˆ—è¡¨çš„å½¢å¼è¾“å‡ºæ¯ä¸ªç”¨æˆ·å¯èƒ½æ„Ÿå…´è¶£çš„é¢†åŸŸï¼Œidå­—æ®µä¸ºæ ‡å·ï¼Œinterestså­—æ®µä¸ºé¢†åŸŸï¼Œå¤šä¸ªé¢†åŸŸé‡‡ç”¨åˆ—è¡¨ï¼Œè¾“å‡ºä¸­æ–‡ã€‚\n",
    "prompt4dynamicprofile": "æ¯ä¸ªæ ‡å·åé¢æ˜¯ä¸€ä¸ªç”¨æˆ·çš„è¯„è®ºï¼Œpostä¸ºä¸Šæ–‡ï¼Œreplyä¸ºå½“å‰ç”¨æˆ·çš„å›å¤ï¼Œè¯·ä»¥jsonåˆ—è¡¨çš„å½¢å¼è¾“å‡ºå›å¤çš„æ¯ä¸ªç”¨æˆ·å¯èƒ½æ„Ÿå…´è¶£çš„é¢†åŸŸï¼Œå½“å‰å›å¤å¯¹ä¸Šæ–‡çš„æ”¯æŒç¨‹åº¦ï¼Œä»¥åŠå’Œä¸Šæ–‡çš„ç›¸å…³æ€§ï¼Œidå­—æ®µä¸ºæ ‡å·ï¼Œinterestså­—æ®µä¸ºé¢†åŸŸï¼Œå¤šä¸ªé¢†åŸŸé‡‡ç”¨åˆ—è¡¨ï¼Œsupport_scoreä¸ºæ”¯æŒç¨‹åº¦ï¼Œrelative_scoreä¸ºç›¸å…³æ€§ç¨‹åº¦ï¼Œè¾“å‡ºä¸­æ–‡ï¼Œæ”¯æŒç¨‹åº¦å’Œç›¸å…³æ€§ç¨‹åº¦æ‰“åˆ†1-10ã€‚è¾“å‡ºç»“æœä¸ºå¯è§£æçš„jsonã€‚\n",
    "prompt4behavior_stepbystep": "åšä¸»ä»‹ç»ï¼š\n{blogger_profile}\n\n{user_count}ä¸ªç”¨æˆ·ä»‹ç»ï¼š \n{followers_profile}\n\näº§å“ä»‹ç»ï¼š\n{product_info}\n\nè¾“å‡ºè¦æ±‚ï¼šæ¯ä¸ªç”¨æˆ·çš„å…´è¶£ç‚¹åœ¨interestå­—æ®µã€æ”¯æŒåº¦åœ¨support_scoreå­—æ®µï¼Œæµè§ˆæ–°äº§å“{product_name}çš„ä»‹ç»åï¼Œæ ¹æ®å…´è¶£ç‚¹å’Œæ”¯æŒåº¦æ¨¡æ‹Ÿæ¯ä¸ªç”¨æˆ·åšå‡ºåŠ¨ä½œï¼ˆå¿½ç•¥äº§å“æˆ–è¯„è®ºäº§å“ï¼‰ã€‚\n1ã€åŠ¨ä½œåŒ…æ‹¬å¿½ç•¥ignoreæˆ–è¯„è®ºcommentï¼Œè¾“å‡ºåœ¨actionå­—æ®µï¼›\n2ã€è‹¥åŠ¨ä½œä¸ºcommentï¼Œåˆ™æ ¹æ®ç”¨æˆ·å·²çŸ¥çš„å…´è¶£ç‚¹å’Œæ”¯æŒåº¦ï¼Œæ¥è€ƒè™‘ç”¨æˆ·å¯¹å‘å¸ƒçš„{product_type}äº§å“{product_name}æ˜¯å¦æœ‰éœ€æ±‚ï¼Œæ ¹æ®éœ€æ±‚æ¥æ¨¡æ‹Ÿç”¨æˆ·çš„è¯­æ°”ç”Ÿæˆé’ˆå¯¹äº§å“{product_name}çš„è¯„è®ºï¼Œè¾“å‡ºåœ¨new_commentå­—æ®µï¼Œ15å­—å†…ï¼›\n3ã€è‹¥åŠ¨ä½œä¸ºcommentï¼Œæ ¹æ®ç”Ÿæˆçš„è¯„è®ºé¢„æµ‹æ¯æ¡è¯„è®ºè´­ä¹°{product_name}çš„å€¾å‘ï¼Œè¾“å‡ºåœ¨purchase_likelihoodå­—æ®µï¼Œæ‰“åˆ†èŒƒå›´ï¼š1ï¼ˆä¸å¯èƒ½è´­ä¹°ï¼‰åˆ°10ï¼ˆå¾ˆå¯èƒ½è´­ä¹°ï¼‰ï¼›\n4ã€æ•´ä½“ç»“æœjsonæ ¼å¼è¾“å‡ºï¼Œé¢„æµ‹çš„actionçš„ä¸ªæ•°å’ŒåŸæœ‰ç”¨æˆ·æ•°ä¿æŒä¸€è‡´ï¼Œä¿ç•™åŸæœ‰ç”¨æˆ·idï¼Œinterestå’Œsupport_scoreå­—æ®µï¼Œè¯·ä¿è¯è¾“å‡ºç»“æœä¸ºå¯è§£æçš„jsonï¼Œå¦‚{\"2737421304\": {\"interests\": [\"å®¶åº­\", \"å¨±ä¹\"], \"support_score\": 7, \"action\": \"comment\", \"new_comment\": \"é€‚åˆå®¶åº­äº²å­æ´»åŠ¨\", \"purchase_likelihood\": 7}ã€‚",
    "prompt4behavior_wo_profile": "ç”¨æˆ·å†å²è¯„è®ºï¼š\n{followers_comments}\n\näº§å“ä»‹ç»ï¼š\n{product_info}\n\nè¾“å‡ºè¦æ±‚ï¼šæµè§ˆæ–°äº§å“{product_name}çš„ä»‹ç»åï¼Œæ ¹æ®å†å²è¯„è®ºæ¨¡æ‹Ÿæ¯ä¸ªç”¨æˆ·åšå‡ºåŠ¨ä½œï¼ˆå¿½ç•¥äº§å“æˆ–è¯„è®ºäº§å“ï¼‰ã€‚\n1ã€åŠ¨ä½œåŒ…æ‹¬å¿½ç•¥ignoreæˆ–è¯„è®ºcommentï¼Œè¾“å‡ºåœ¨actionå­—æ®µï¼›\n2ã€è‹¥åŠ¨ä½œä¸ºcommentï¼Œåˆ™æ ¹æ®ç”¨æˆ·å†å²è¯„è®ºï¼Œæ¥è€ƒè™‘ç”¨æˆ·å¯¹å‘å¸ƒçš„{product_type}äº§å“{product_name}æ˜¯å¦æœ‰éœ€æ±‚ï¼Œæ ¹æ®éœ€æ±‚æ¥æ¨¡æ‹Ÿç”¨æˆ·çš„è¯­æ°”ç”Ÿæˆé’ˆå¯¹äº§å“{product_name}çš„è¯„è®ºï¼Œè¾“å‡ºåœ¨new_commentå­—æ®µï¼Œ15å­—å†…ï¼›\n3ã€è‹¥åŠ¨ä½œä¸ºcommentï¼Œæ ¹æ®ç”Ÿæˆçš„è¯„è®ºé¢„æµ‹æ¯æ¡è¯„è®ºè´­ä¹°{product_name}çš„å€¾å‘ï¼Œè¾“å‡ºåœ¨purchase_likelihoodå­—æ®µï¼Œæ‰“åˆ†èŒƒå›´ï¼š1ï¼ˆä¸å¯èƒ½è´­ä¹°ï¼‰åˆ°10ï¼ˆå¾ˆå¯èƒ½è´­ä¹°ï¼‰ï¼›\n4ã€æ•´ä½“ç»“æœjsonæ ¼å¼è¾“å‡ºï¼Œé¢„æµ‹çš„actionçš„ä¸ªæ•°å’ŒåŸæœ‰ç”¨æˆ·æ•°ä¿æŒä¸€è‡´ï¼Œä¿ç•™åŸæœ‰ç”¨æˆ·idï¼Œè¯·ä¿è¯è¾“å‡ºç»“æœä¸ºå¯è§£æçš„jsonï¼Œå¦‚{\"2737421304\": {\"action\": \"comment\", \"new_comment\": \"é€‚åˆå®¶åº­äº²å­æ´»åŠ¨\", \"purchase_likelihood\": 7}ã€‚",
    "prompt4behavior_wo_cot": "åšä¸»ä»‹ç»ï¼š\n{blogger_profile}\n\n{user_count}ä¸ªç”¨æˆ·ä»‹ç»ï¼š \n{followers_profile}\n\näº§å“ä»‹ç»ï¼š\n{product_info}\n\nè¾“å‡ºè¦æ±‚ï¼šå¯¹äºæ¯ä¸ªç”¨æˆ·ï¼Œæ ¹æ®å…¶å…´è¶£ç‚¹å’Œæ”¯æŒåº¦ï¼Œåœ¨æµè§ˆæ–°äº§å“{product_name}ä»‹ç»åè¿›è¡Œæ¨¡æ‹ŸåŠ¨ä½œï¼ŒåŒ…æ‹¬å¿½ç•¥(ignore)æˆ–è¯„è®º(comment)ã€‚åŠ¨ä½œä¿¡æ¯è®°å½•åœ¨actionå­—æ®µã€‚\n\nè‹¥åŠ¨ä½œä¸ºè¯„è®º(comment)ï¼š\n- æ ¹æ®ç”¨æˆ·å·²çŸ¥çš„å…´è¶£ç‚¹å’Œæ”¯æŒåº¦ï¼Œè€ƒè™‘ç”¨æˆ·å¯¹å‘å¸ƒçš„{product_type}äº§å“{product_name}æ˜¯å¦æœ‰éœ€æ±‚ã€‚\n- æ¨¡æ‹Ÿç”¨æˆ·è¯­æ°”ç”Ÿæˆé’ˆå¯¹äº§å“{product_name}çš„è¯„è®ºï¼Œè¯„è®ºå†…å®¹è®°å½•åœ¨new_commentå­—æ®µï¼ˆ15å­—å†…ï¼‰ã€‚\n- é’ˆå¯¹æ¯æ¡è¯„è®ºé¢„æµ‹è´­ä¹°{product_name}çš„å€¾å‘ï¼Œè¾“å‡ºåœ¨purchase_likelihoodå­—æ®µï¼Œæ‰“åˆ†èŒƒå›´ï¼š1ï¼ˆä¸å¯èƒ½è´­ä¹°ï¼‰åˆ°10ï¼ˆå¾ˆå¯èƒ½è´­ä¹°ï¼‰ã€‚\n\næ•´ä½“ç»“æœä»¥JSONæ ¼å¼è¾“å‡ºï¼Œä¿æŒé¢„æµ‹çš„åŠ¨ä½œä¸ªæ•°ä¸åŸæœ‰ç”¨æˆ·æ•°ä¸€è‡´ï¼ŒåŒæ—¶ä¿ç•™åŸæœ‰ç”¨æˆ·idã€å…´è¶£ç‚¹(interests)å’Œæ”¯æŒåº¦(support_score)å­—æ®µã€‚å¦‚{\"2737421304\": {\"interests\": [\"å®¶åº­\", \"å¨±ä¹\"], \"support_score\": 7, \"action\": \"comment\", \"new_comment\": \"é€‚åˆå®¶åº­äº²å­æ´»åŠ¨\", \"purchase_likelihood\": 7}ã€‚"
    
}

openai.api_type = "open_ai"
#openai.api_base = "https://api.openai.com/v1"
# openai.api_base = "http://172.24.70.1:38093/v1"
openai.api_version=""
#openai.api_key = "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"
# openai.api_key = "ZG9uZ21lbmduYW46MHZsQTNMNjAyWWlOWEtrSjdtcEE2VWhEOW5ZZzF2NUM="

import re

def remove_angle_brackets(input_string):
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å°–æ‹¬å·å†…çš„å†…å®¹
    pattern = re.compile(r'<.*?>')
    # ä½¿ç”¨ sub æ–¹æ³•å°†åŒ¹é…åˆ°çš„å†…å®¹æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
    result = re.sub(pattern, '', input_string)
    if len(result.strip()) == 0:
        result = input_string
    return result

@retry(stop_max_attempt_number=10, wait_fixed=1000)
def get_response(text, model="gpt-3.5-turbo"):
    messages = []
    messages = [{"role": "user", "content": text}]
    # print("messages")
    # print(messages)
    if model == "gpt-3.5-turbo" or model == "gpt-4":
        openai.api_base = "http://172.24.70.1:38093/v1"
        openai.api_key = "ZG9uZ21lbmduYW46MHZsQTNMNjAyWWlOWEtrSjdtcEE2VWhEOW5ZZzF2NUM="
    else:
        openai.api_base = "https://test-0121-v6-rollout.app.msh.team/v1"
        openai.api_key = "12312"
    result = openai.ChatCompletion.create(model=model, messages=messages, temperature=0.95)
    response = result['choices'][0]['message']['content']
    print("response")
    print(response)
    return response


@retry(stop_max_attempt_number=10, wait_fixed=1000)
def get_response_gpt(text, model="gpt-3.5-turbo"):
    messages = []
    messages = [{"role": "user", "content": text}]
    # print("messages")
    # print(messages)
    result = openai.ChatCompletion.create(model=model, messages=messages, temperature=0.95)
    response = result['choices'][0]['message']['content']
    print("response")
    print(response)
    return response

# åŠ è½½å¤§V
def load_seeds(round, static_data):
    global product
    seed_set = []
    for i in range(round+1):
        filename = "t100/%s_r%s_uid.txt" % (product, i)
        for line in open(filename, "r", encoding="utf-8"):
            line = line.strip("\n")
            fields = line.split("\t")
            if len(fields) > 0:
                if str(fields[0]) not in seed_set and static_data[fields[0]]["user_followers"] > 100000:
                    seed_set.append(str(fields[0]))
        print(len(seed_set))
    return set(seed_set)

# åŠ è½½äº’åŠ¨ç½‘ç»œå›¾
def load_interaction_graph():
    global relation_file
    user_dict = {}
    interaction_graph = len(user_dict) * len(user_dict)
    return interaction_graph

# åŠ è½½é™æ€ä¿¡æ¯ï¼šç”¨æˆ·IDï¼Œé™æ€profile
def load_static_profile():
    global static_file
    with open(static_file, 'r', encoding='utf-8') as file:
        static_data = json.load(file)
    return static_data

# åŠ è½½åŠ¨æ€ä¿¡æ¯ï¼šç”¨æˆ·IDï¼Œå†å²è¯„è®ºç­‰
def load_dynamic_profile():
    global dynamic_file
    with open(dynamic_file, 'r', encoding='utf-8') as file:
        dynamic_data = json.load(file)
    return dynamic_data

def load_features():
    global feature_file
    with open(feature_file, 'r', encoding='utf-8') as file:
        feature_data = json.load(file)
    return feature_data

# æ‰€æœ‰å¤§Vé‡‡æ ·è‡³å°‘20ä¸ªç”¨æˆ·ï¼Œè¾“å‡ºåˆ°æ–‡ä»¶user_id\tlabel 0:v,1:nv
def sample_user(static_profile, dynamic_profile, seed_set):
    v0_users = {}
    # for line in open("./%s.v0/step1.sample.user.res" % product, "r", encoding="utf-8"):
    #     line = line.strip()
    #     fields = line.split("\t")
    #     v0_users.setdefault(fields[0], fields[1])
    # print(v0_users)
    sample_f = open("./%s/step1.sample.user.res" % product, "w+", encoding="utf-8")
    for user_id in static_profile:
        if user_id not in seed_set:
            continue
        # if user_id in dynamic_profile and static_profile[user_id]["user_followers"] > 100000:
        if user_id in dynamic_profile and static_profile[user_id]["user_followers"] > 100000:
            interact_list = list(set([uttr["interact_id"] for uttr in dynamic_profile[user_id]]))
            reserved_list = []
            backup_list = []
            for interact_id in interact_list:
                if static_profile[str(interact_id)]["user_followers"] > 100000:
                    # reserved_list.append(str(interact_id)+","+str(static_profile[str(interact_id)]["user_followers"]))
                    reserved_list.append(str(interact_id))
                    # reserved_list.append(str(interact_id)+"$$$"+str(interact_dict[str(interact_id)]))
                else:
                    # backup_list.append(str(interact_id)+","+str(static_profile[str(interact_id)]["user_followers"]))
                    backup_list.append(str(interact_id))
                    # backup_list.append(str(interact_id)+"$$$"+str(interact_dict[str(interact_id)]))
            backup_list = random.sample(backup_list, min(len(backup_list), 20))
            if len(reserved_list) > 0:
                reserved_list.extend(backup_list)
            else:
                reserved_list = backup_list
            if user_id in v0_users:
                reserved_list = v0_users[user_id].split(":")
            else:
                print("not found %s" % user_id)
            reserved_list = random.sample(reserved_list, min(len(reserved_list), 20))
            # interact_list_detail = [uttr for uttr in dynamic_profile[user_id] if str(uttr["interact_id"]) in reserved_list]
            sample_f.write("%s\t%s\n" % (user_id, ":".join(reserved_list)))
    return

# é€‰æ‹©influencer/éšæœºoræŒ‰æ¨¡å‹é€‰ï¼Œè¾“å‡ºåˆ°æ–‡ä»¶
def influencer_pre_selection(gt_ids, static_file, feature_dict):
    influencer_candidate = []
    for line in open("./%s/step1.sample.user.res" % product, "r", encoding="utf-8"):
        line = line.strip("\n")
        fields = line.split("\t")
        influencer_candidate.append(fields[0])
    sample_influencer_by_random = {user_id: static_file[user_id]["user_followers"] for user_id in influencer_candidate}
    sorted_sample_influencer_by_random = dict(sorted(sample_influencer_by_random.items(), key=lambda item: item[1], reverse=True))
    sample_influencer_by_random = list(itertools.islice(sorted_sample_influencer_by_random.keys(), 200))
    sample_influencer_by_random = [key + "\t" + static_file[key]["user_name"] + "\t" + str(static_file[key]["user_followers"]) for key in sample_influencer_by_random]
    # sample_influencer_by_random[0:4] = gt_ids
    filename = '../models/random_forest_model_v9.joblib'
    rf_classifier = joblib.load(filename)
    feature_list = [feature_dict[user_id] for user_id in influencer_candidate]
    # random_feature_list = [feature_dict[user_id] for user_id in sample_influencer_by_random]
    # random_scores = rf_classifier.predict_proba(random_feature_list)
    # random_scores = [score[1] for score in random_scores]
    # random_selection_scores = {sample_influencer_by_random[i]: random_scores[i] for i in range(len(sample_influencer_by_random))}
    # random_selection_scores = dict(sorted(random_selection_scores.items(), key=lambda item: item[1], reverse=True))
    # random_selection_scores = list(random_selection_scores.items())
    # sample_influencer_by_random = [key + "\t" + static_file[key]["user_name"] + "\t" + str(value) for key, value in random_selection_scores[0:200]]
    scores = rf_classifier.predict_proba(feature_list)
    scores = [score[1] for score in scores]
    pre_selection_scores = {influencer_candidate[i]: scores[i] for i in range(len(influencer_candidate))}
    pre_selection_scores = dict(sorted(pre_selection_scores.items(), key=lambda item: item[1], reverse=True))
    pre_selection_scores = list(pre_selection_scores.items())
    # print(pre_selection_scores)
    sample_influencer_by_model = [key + "\t" + static_file[key]["user_name"] + "\t" + str(value) for key, value in pre_selection_scores[0:200]]
    pre_selection_f1 = open("./%s/step2.influencer.pre.selection.by.sample" % product, "w+", encoding="utf-8")
    pre_selection_f1.write("\n".join(sample_influencer_by_random))
    pre_selection_f1.close()
    pre_selection_f2 = open("./%s/step2.influencer.pre.selection.by.model" % product, "w+", encoding="utf-8")
    pre_selection_f2.write("\n".join(sample_influencer_by_model))
    pre_selection_f2.close()
    return

def request_score(filename, data_map, prompt, request_batch_size):
    static_f = open(filename, "a+", encoding="utf-8")
    data_list = list(data_map.items())
    for i in range(int(len(data_list)/request_batch_size)+1):
        # if i != 1528:
        #     continue
        user_list = [item[0] for item in data_list[i*request_batch_size: (i+1)*request_batch_size]]
        description_list = [item[1] for item in data_list[i*request_batch_size: (i+1)*request_batch_size]]
        numbered_list = [(i + 1, item) for i, item in enumerate(description_list)]
        request_string = '\n'.join([f'{index}: {value}' for index, value in numbered_list])
        result_dict = {}
        try:
            response = get_response(prompt + request_string, model="kimi")
            # scores = json.loads(get_response(prompt + request_string, model="gpt-4"))
            # scores = json.loads(get_response(prompt + request_string, model="kimi"))
            # result_dict = {user_list[j]: scores[j] for j in range(len(user_list))}
        except:
            try:
                response = get_response(prompt + request_string, model="kimi")
                # scores = json.loads(get_response(prompt + request_string, model="kimi"))
                # result_dict = {user_list[j]: scores[j] for j in range(len(user_list))}
            except:
                try:
                    response = get_response(prompt + request_string, model="kimi")
                    # scores = json.loads(get_response(prompt + request_string, model="kimi"))
                    # result_dict = {user_list[j]: scores[j] for j in range(len(user_list))}
                except:
                    print("request_score failed idx=%s" % i)
        # static_f.write(json.dumps(result_dict, ensure_ascii=False))
        static_f.write(json.dumps(user_list, ensure_ascii=False))
        static_f.write(response)
        static_f.write("\n")
        print("request_score process idx=%s" % i)
    static_f.close()

# æ‰€æœ‰ç”¨æˆ·ç”Ÿæˆprofileï¼Œè¾“å‡ºåˆ°æ–‡ä»¶
def follower_profile_reasoning(static_file, request_type):
    #static profile/dynamic profile
    # user_id, user_gender, user_followers, user_friends, user_description
    # comments areas / support score / relative score
    interaction_map = {}
    existed_static_map = {}
    existed_dynamic_map = {}
    for line in open("./%s/step3.follower.profile.reasoning.dynamic" % product, "r", encoding="utf-8"):
        json_tokens = json.loads(line.strip())
        for hybrid_user in json_tokens:
            user_id = hybrid_user.split(":")[0]
            if user_id not in existed_dynamic_map:
                existed_dynamic_map.setdefault(user_id, 1)
    print("len of existed_dynamic_map: %s" % len(existed_dynamic_map))
    # sample_user_f = open("./%s/step1.sample.user.res.sample.interact.res" % product, "w+", encoding="utf-8")
    for line in open("./%s/step1.sample.user.res" % product, "r", encoding="utf-8"):
        line = line.strip("\n")
        fields = line.split("\t")
        interact_user = fields[1].split(":")
        # if len(interact_user) > 20:
        #     interact_user = random.sample(interact_user, 20)
        # sample_user_f.write("%s\t%s\n" % (str(fields[0]), ":".join(interact_user)))
        # if str(fields[0]) not in existed_dynamic_map:
        interaction_map.setdefault(str(fields[0]), interact_user)
            # print("request user %s for interaction map" % str(fields[0]))
    # sample_user_f.close()
    static_map = {user_id: static_file[user_id]["user_description"] for user_id in interaction_map}
    print("request size for static: %s" % len(static_map))
    # request_score("./%s/step3.follower.profile.reasoning.static" % product, static_map, PROMPT_DICT["prompt4staticprofile"], 10)
    # return
    idx = 0
    for line in open("./%s/step3.follower.profile.reasoning.static" % product, "r", encoding="utf-8"):
        line = line.strip()
        json_tokens = json.loads(line)
        idx += 1
        # print(idx)
        for user_id in json_tokens:
            # print(user_id)
            # print(json_tokens[user_id])
            existed_static_map.setdefault(user_id, json_tokens[user_id])
    # print(len(existed_static_map))
    static_map = existed_static_map
    dynamic_map = {}
    for user_id in interaction_map:
        existed_users = interaction_map[user_id]
        print(existed_users)
        interact_dict = {str(uttr["interact_id"]): "post: " + remove_angle_brackets(uttr["text_raw"]) + " reply: " + remove_angle_brackets(uttr["text_comment"]) for uttr in
                     dynamic_profile[user_id] if str(uttr["interact_id"]) in existed_users}
        for interact_id in interact_dict:
            new_user_id = user_id + ":" + interact_id
            comments = interact_dict[interact_id]
            dynamic_map.setdefault(new_user_id, comments)
    # print(dynamic_map)
    print("request size for dynamic: %s" % len(dynamic_map))
    # request_score("./%s/step3.follower.profile.reasoning.dynamic" % product, dynamic_map, PROMPT_DICT["prompt4dynamicprofile"], 10)
    # return
    for line in open("./%s/step3.follower.profile.reasoning.dynamic" % product, 'r', encoding='utf-8'):
        line = line.strip()
        # print(line)
        json_tokens = json.loads(line)
        # print(json_tokens)
        # print(type(json_tokens))
        for hybrid_user in json_tokens:
            if hybrid_user in dynamic_map and type(dynamic_map[hybrid_user]) == str:
                # print("hybrid_user")
                # print(dynamic_map[hybrid_user])
                comment = dynamic_map[hybrid_user].split("reply:")[1]
                # print("comment")
                # print(comment)
                if type(json_tokens[hybrid_user]) == str:
                    # print(json_tokens[hybrid_user])
                    dynamic_map[hybrid_user] = json.loads(json_tokens[hybrid_user])
                else:
                    dynamic_map[hybrid_user] = json_tokens[hybrid_user]
                # print(dynamic_map[hybrid_user])
                
                dynamic_map[hybrid_user].setdefault("comment", comment)
    # print(dynamic_map)
    # with open("./%s/step3.follower.profile.reasoning.dynamic" % product, 'r', encoding='utf-8') as file:
    #     dynamic_map = json.load(file)
    new_dynamic_map = {}
    for hybrid_user in dynamic_map:
        [user_id, interact_id] = hybrid_user.split(":")
        # print(dynamic_map[hybrid_user])
        # print(type(dynamic_map[hybrid_user]))
        if type(dynamic_map[hybrid_user]) == str:
            continue
        interests = dynamic_map[hybrid_user]["interests"]
        relative_score = dynamic_map[hybrid_user]["relative_score"]
        supports_score = dynamic_map[hybrid_user]["support_score"]
        comment = dynamic_map[hybrid_user]["comment"]
        if user_id not in new_dynamic_map:
            item_interests = {interact_id: interests}
            item_supports = {interact_id: supports_score}
            item_relatives = {interact_id: relative_score}
            item_comments = {interact_id: comment}
            item = {}
            item["ids"] = [interact_id]
            item["interests"] = item_interests
            item["supports"] = item_supports
            item["relatives"] = item_relatives
            item["comments"] = item_comments
            new_dynamic_map.setdefault(user_id, item)
        else:
            item_ids = new_dynamic_map[user_id]["ids"]
            item_interests = new_dynamic_map[user_id]["interests"]
            item_supports = new_dynamic_map[user_id]["supports"]
            item_relatives = new_dynamic_map[user_id]["relatives"]
            item_comments = new_dynamic_map[user_id]["comments"]
            item_ids.append(interact_id)
            item_interests.setdefault(interact_id, interests)
            item_supports.setdefault(interact_id, supports_score)
            item_relatives.setdefault(interact_id, relative_score)
            item_comments.setdefault(interact_id, comment)
            new_dynamic_map[user_id]["ids"] = item_ids
            new_dynamic_map[user_id]["interests"] = item_interests
            new_dynamic_map[user_id]["supports"] = item_supports
            new_dynamic_map[user_id]["relatives"] = item_relatives
            new_dynamic_map[user_id]["comment"] = item_comments
    profile_dict = {}
    influencer_candidates = []
    for line in open("./%s/step2.influencer.pre.selection.by.%s" % (product, request_type), "r", encoding="utf-8"):
        influencer_candidates.append(line.strip().split("\t")[0])
    for user_id in influencer_candidates:
        item = {}
        item["user_name"] = static_file[user_id]["user_name"]
        item["user_gender"] = static_file[user_id]["user_gender"]
        item["user_followers"] = static_file[user_id]["user_followers"]
        item["user_friends"] = static_file[user_id]["user_friends"]
        item["interests"] = []
        item["followers_profiles"] = {}
        if user_id in static_map:
            item["interests"] = static_map[user_id]["interests"]
            if user_id in new_dynamic_map:
                followers_profiles = {}
                followers_interests = new_dynamic_map[user_id]["interests"]
                followers_supports = new_dynamic_map[user_id]["supports"]
                followers_relatives = new_dynamic_map[user_id]["relatives"]
                followers_comments = new_dynamic_map[user_id]["comments"]
                for interact_id in followers_interests:
                    interact_interests = followers_interests[interact_id]
                    interact_supports = followers_supports[interact_id]
                    interact_relatives = followers_relatives[interact_id]
                    interact_comments = followers_comments[interact_id]
                    interact_item = {}
                    interact_item["user_name"] = static_file[interact_id]["user_name"]
                    interact_item["user_gender"] = static_file[interact_id]["user_gender"]
                    interact_item["user_followers"] = static_file[interact_id]["user_followers"]
                    interact_item["user_friends"] = static_file[interact_id]["user_friends"]
                    interact_item["interests"] = interact_interests
                    interact_item["supports"] = interact_supports
                    interact_item["relatives"] = interact_relatives
                    interact_item["comments"] = interact_comments
                    followers_profiles.setdefault(interact_id, interact_item)
                item["followers_profiles"] = followers_profiles
        profile_dict.setdefault(user_id, item)
    profile_f = open("./%s/step3.follower.profile.%s" % (product, request_type), "w+", encoding="utf-8")
    profile_f.write(json.dumps(profile_dict, ensure_ascii=False, indent=2))
    profile_f.close()
    return

# æ‰€æœ‰influencer candidatesè¿›è¡Œbehavioré¢„æµ‹/é‡‡çº³profileå’Œä¸é‡‡çº³profileï¼Œè¾“å‡ºåˆ°æ–‡ä»¶
def follower_behavior_prediction(request_type, prompt_type):
    result_dict = {}
    influencer_candidates = {}
    for line in open("./%s/step4.follower.behavior.prediction.%s" % (product, prompt_type), "r", encoding="utf-8"):
        line = line.strip()
        fields = line.split("\t")
        if fields[0] not in result_dict:
            result_dict.setdefault(fields[0], 1)
    result_f = open("./%s/step4.follower.behavior.prediction.%s" % (product, prompt_type), "a+", encoding="utf-8")
    with open("./%s/step3.follower.profile.%s" % (product, request_type), 'r', encoding='utf-8') as file:
        influencer_candidates = json.load(file)
    for user_id in influencer_candidates:
        if user_id in result_dict:
            continue
        print(user_id)
        item = {}
        item["user_name"] = influencer_candidates[user_id]["user_name"]
        item["user_gender"] = influencer_candidates[user_id]["user_name"]
        item["user_followers"] = influencer_candidates[user_id]["user_followers"]
        item["user_friends"] = influencer_candidates[user_id]["user_friends"]
        item["interests"] = influencer_candidates[user_id]["interests"]
        blogger_profile = json.dumps(item, ensure_ascii=False)
        user_count = len(influencer_candidates[user_id]["followers_profiles"])
        followers_profile = json.dumps(influencer_candidates[user_id]["followers_profiles"], ensure_ascii=False)
        followers_comments = {interact_id: influencer_candidates[user_id]["followers_profiles"][interact_id]["comments"] for interact_id in influencer_candidates[user_id]["followers_profiles"]}
        followers_comments = json.dumps(followers_comments, ensure_ascii=False)
        product_name = PRODUCT_DETAIL[product]["product_name"]
        product_type = PRODUCT_DETAIL[product]["product_type"]
        product_info = PRODUCT_DETAIL[product]["product_info"]
        prompt = PROMPT_DICT[prompt_type]
        prompt = prompt.replace("{blogger_profile}", blogger_profile)
        prompt = prompt.replace("{followers_profile}", followers_profile)
        prompt = prompt.replace("{followers_comments}", followers_comments)
        prompt = prompt.replace("{product_name}", product_name)
        prompt = prompt.replace("{product_type}", product_type)
        prompt = prompt.replace("{product_info}", product_info)
        prompt = prompt.replace("{user_count}", str(user_count))
        response = ""
        print(prompt)
        try:
            # response = get_response(prompt, model="gpt-4")
            response = get_response(prompt, model="kimi")
            response = response[response.find("{"):(response.rfind("}") + 1)]
            response = response.replace("\n", "")
            print(response)
        except:
            response = {}
        result_f.write("%s\t%s\n" % (user_id, response))
    result_f.close()
    return

# æ¯ä¸ªinfluencerè®¡ç®—äº¤äº’weightï¼Œè¾“å‡ºåˆ°æ–‡ä»¶
def influencer_ranking(static_profile, dynamic_file, request_type, prompt_type, top_k, sample_k, ranking_policy="simulation"):
    name2id = {}
    whole_users = []
    before_ranking_list = []
    before_ranking_ids = []
    idx = 0
    ranking_dict = {}
    for line in open("./%s/step2.influencer.pre.selection.by.sample" % (product)):
        line = line.strip("\n")
        fields = line.split("\t")
        user_id = fields[0]
        user_name = static_profile[user_id]["user_name"]
        if user_name.find("å®˜æ–¹") != -1 or user_name.find("å¹³å°") != -1:
            continue
        whole_users.append(user_name)
    for line in open("./%s/step2.influencer.pre.selection.by.%s" % (product, request_type)):
        line = line.strip("\n")
        fields = line.split("\t")
        user_id = fields[0]
        user_name = static_profile[user_id]["user_name"]
        if user_name.find("å®˜æ–¹") != -1 or user_name.find("å¹³å°") != -1:
            continue
        before_ranking_ids.append(user_id)
        before_ranking_list.append(user_name)
        # whole_users.append(user_name)
    # for line in open("./%s/step4.model.follower.behavior.prediction" % product, "r", encoding="utf-8"):
    #     line = line.strip("\n")
    #     fields = line.split("\t")
    #     user_id = fields[0]
    #     user_name = static_profile[user_id]["user_name"]
    #     whole_users.append(user_name)
    behavior_result = {}
    for line in open("./%s/step4.follower.behavior.prediction.%s" % (product, prompt_type), "r", encoding="utf-8"):
        line = line.strip("\n")
        # print(line)
        fields = line.split("\t")
        # print(fields[1])
        if len(fields[1].strip()) == 0:
            continue
        behavior_result.setdefault(fields[0], fields[1])
    for user_id in before_ranking_ids:
        if user_id not in behavior_result:
            continue
        user_name = static_profile[user_id]["user_name"]
        if user_name not in name2id:
            name2id.setdefault(user_name, user_id)
        # print(user_id)
        # before_ranking_list.append(user_name)
        continue_flag = 0
        followers_count = static_profile[user_id]["user_followers"]
        # huohuasiwei
        # if followers_count > 100000 and followers_count < 200000:
        #     continue_flag = 1
        # if followers_count > 400000 and followers_count < 600000:
        #     continue_flag = 1
        # if followers_count > 2000000 and followers_count < 3000000:
        #     continue_flag = 1

        # brush
        # if followers_count > 1500000 and followers_count < 2500000:
        #     continue_flag = 1
        # if followers_count > 3000000 and followers_count < 4000000:
        #     continue_flag = 1
        # if followers_count > 6000000 and followers_count < 7000000:
        #     continue_flag = 1

        # # cream
        # if followers_count > 100000 and followers_count < 1000000:
        #     continue_flag = 1
        # if continue_flag == 0:
        #     continue

        # yunjing
        # if followers_count > 100000 and followers_count < 200000:
        #     continue_flag = 1
        # if followers_count > 300000 and followers_count < 400000:
        #     continue_flag = 1
        # if followers_count > 2000000 and followers_count < 2500000:
        #     continue_flag = 1
        # if followers_count > 6500000 and followers_count < 7000000:
        #     continue_flag = 1
        # if continue_flag == 0:
        #     continue
        # before_ranking_list.append(user_name)
        response = behavior_result[user_id]
        # print(user_id)
        # print(response)
        # print(response)
        response = response.replace("null", "0")
        response = response.replace("...", "")
        response = response.replace(" ", "")
        # print(response)
        if len(response.split("ï¼š")) > 1 and response.find("ï¼š") < 10:
            response = "".join(response.split("ï¼š")[1:])
        if response[0:5] == "è¾“å‡ºç»“æœï¼š":
            response = response[5:]
        if response[0:3] == "è¾“å‡ºï¼š":
            response = response[3:]
        try:
            comments = json.loads(response)
        except:
            try:
                comments = json.loads("[" + response + "]")
            except:
                comments = json.loads(response + "}")
            #     # print(response)
            #     try:
            #         comments = json.loads(response + "}")
            #     except:
            #         comments = json.loads(response.replace("'", "\""))
        avg_score = 0
        effective_count = 0
        
        if type(comments) == list:
            comments = comments[0]
            comments_ids = random.sample(list(comments), min(sample_k, len(comments)))
            # print("sample k: %s len of comments: %s len of ids: %s" % (sample_k, len(comments), len(comments_ids)))
            # print(len(comments_ids))
            for interact_comment in comments:
                if interact_comment not in comments_ids:
                    continue
                # print("interact_comment")
                # print(interact_comment)
                comment = comments[interact_comment]
                # print("comment")
                # print(comment)
                if "action" in comment and comment["action"] == "comment" and "purchase_likelihood" in comment:
                    # print(comment["purchase_likelihood"])
                    if comment["purchase_likelihood"] == "" or comment["purchase_likelihood"] is None:
                        comment["purchase_likelihood"] = 0
                    if int(comment["purchase_likelihood"]) > 0:
                        effective_count += 1
                    avg_score += int(comment["purchase_likelihood"])
        else:
            comments_ids = random.sample(list(comments), min(sample_k, len(comments)))
            # print(len(comments_ids))
            # print("sample k: %s len of comments: %s len of ids: %s" % (sample_k, len(comments), len(comments_ids)))
            # print(comments)
            for interact_id in comments:
                if interact_id not in comments_ids:
                    continue
                # print(interact_id)
                comment = comments[interact_id]
                # print("comment")
                # print(comment)
                # if "purchase_likelihood" in comment:
                if "action" in comment and comment["action"] == "comment" and "purchase_likelihood" in comment:
                    # print(comment["purchase_likelihood"])
                    if comment["purchase_likelihood"] == "":
                        comment["purchase_likelihood"] = 0
                    if int(comment["purchase_likelihood"]) > 0:
                        effective_count += 1
                    avg_score += int(comment["purchase_likelihood"])
        # avg_score /= len(comments)
        # if effective_count > 0:
        #     avg_score /= effective_count
        # if len(list(uttr["text_raw"] for uttr in dynamic_file[user_id] if uttr["interact_type"] == "comment"))/len(list(set(uttr["text_raw"] for uttr in dynamic_file[user_id]))) < 10:
        #     continue
        # if idx > 0.5 * len(before_ranking_list):
        #     break
        if idx >= top_k:
            break
        if len(comments) > 0:
            if ranking_policy == "simulation":
                avg_score = avg_score * (len(list(uttr["text_raw"] for uttr in dynamic_file[user_id] if uttr["interact_type"] == "comment"))/(min(sample_k, len(comments))*len(list(set(uttr["text_raw"] for uttr in dynamic_file[user_id])))))
            else:
                avg_score = avg_score/min(sample_k, len(comments))
                # avg_score = (len(list(uttr["text_raw"] for uttr in dynamic_file[user_id] if uttr["interact_type"] == "comment"))/len(list(set(uttr["text_raw"] for uttr in dynamic_file[user_id]))))
        # print("ç”¨æˆ·åï¼š%s\tå¹³å‡åˆ†ï¼š%s\täº’åŠ¨æ•°ï¼š%s\tè¯„è®ºæ€»æ•°ï¼š%s\tæ¨¡æ‹Ÿè¯„è®ºæ•°ï¼š%s\tæœ‰æ•ˆè¯„è®ºæ•°ï¼š%s\tæ— æ•ˆè¯„è®ºæ•°ï¼š%s\tå‘å¸–æ•°ï¼š%s" % (user_name, avg_score, len(dynamic_file[user_id]), len(list(uttr["text_raw"] for uttr in dynamic_file[user_id] if uttr["interact_type"] == "comment")), len(comments), effective_count, len(comments)-effective_count, len(list(set(uttr["text_raw"] for uttr in dynamic_file[user_id])))))
        if user_name not in ranking_dict:
            ranking_dict.setdefault(user_name, avg_score)
        idx += 1
    #print(ranking_dict)
    print("len of ranking dict: %s" % len(ranking_dict))
    sorted_dict = dict(sorted(ranking_dict.items(), key=lambda item: item[1], reverse=True))
    # print(sorted_dict)
    # print(before_ranking_list)
    after_ranking_list = list(itertools.islice(sorted_dict.keys(), 200))
    ranking_ids = [name2id[user_name] for user_name in after_ranking_list]
    # sim_f = open("simulation.txt", "a+", encoding="utf-8")
    # sim_f.write("%s\t%s\n" % (product, json.dumps(ranking_ids, ensure_ascii=False)))
    # sim_f.close()
    return whole_users, before_ranking_list, after_ranking_list

def overall_evaluation(gt_names, predicted_items):
    print(gt_names)
    print(predicted_items)
    # print("after selection")
    # precision_1, recall_1, ndcg_1 = ranking_evaluation(gt_names, selection_names, 1)
    # precision_2, recall_2, ndcg_2 = ranking_evaluation(gt_names, selection_names, 2)
    # precision_5, recall_5, ndcg_5 = ranking_evaluation(gt_names, selection_names, 5)
    # precision_10, recall_10, ndcg_10 = ranking_evaluation(gt_names, selection_names, 10)
    # print("P@1=%.3f, R@1=%.3f, NDCG@1=%.3f" % (precision_1, recall_1, ndcg_1))
    # print("P@2=%.3f, R@2=%.3f, NDCG@2=%.3f" % (precision_2, recall_2, ndcg_2))
    # print("P@5=%.3f, R@5=%.3f, NDCG@5=%.3f" % (precision_5, recall_5, ndcg_5))
    # print("P@10=%.3f, R@10=%.3f, NDCG@10=%.3f" % (precision_10, recall_10, ndcg_10))
    # print("after ranking")
    precision_1, recall_1, ndcg_1 = ranking_evaluation(gt_names, predicted_items, 1)
    precision_2, recall_2, ndcg_2 = ranking_evaluation(gt_names, predicted_items, 2)
    precision_5, recall_5, ndcg_5 = ranking_evaluation(gt_names, predicted_items, 5)
    precision_10, recall_10, ndcg_10 = ranking_evaluation(gt_names, predicted_items, 10)
    print("P@1=%.3f, R@1=%.3f, NDCG@1=%.3f" % (precision_1, recall_1, ndcg_1))
    print("P@2=%.3f, R@2=%.3f, NDCG@2=%.3f" % (precision_2, recall_2, ndcg_2))
    print("P@5=%.3f, R@5=%.3f, NDCG@5=%.3f" % (precision_5, recall_5, ndcg_5))
    print("P@10=%.3f, R@10=%.3f, NDCG@10=%.3f" % (precision_10, recall_10, ndcg_10))
    return precision_5, precision_10, recall_5, recall_10, ndcg_5, ndcg_10
    # return

def display_domain_distribution(display_users):
    print("display users")
    print(display_users)
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
    profile_data = {}
    with open("./%s/step3.follower.profile" % product, "r", encoding='utf-8') as file:
        profile_data = json.load(file)
    domain_dict = {}
    for user_id in profile_data:
        user_name = profile_data[user_id]["user_name"]
        if user_name in display_users:
            interests = profile_data[user_id]["interests"]
            for interest in interests:
                if interest == "æ—…æ¸¸":
                    interest = "æ—…è¡Œ"
                if interest not in domain_dict:
                    domain_dict.setdefault(interest, 1)
                else:
                    domain_dict[interest] += 1
    sorted_dict = dict(sorted(domain_dict.items(), key=lambda item: item[1], reverse=True))
    labels = []
    sizes = []
    total_cnt = 0
    idx = 0
    for domain in sorted_dict:
        if idx == 10:
            break
        cnt = sorted_dict[domain]
        print(domain)
        print(cnt)
        labels.append(domain)
        sizes.append(cnt)
        total_cnt += cnt
        idx += 1
    print(sizes)
    print(total_cnt)
    sizes = [int((i/total_cnt)*100) for i in sizes]
    print(labels)
    print(sizes)
    # é¥¼å›¾çš„é¢œè‰²
    # ç¾é£Ÿ gold
    # ç”Ÿæ´» lightcoral
    # æ—…è¡Œ lightskyblue
    # æ‘„å½± lightgreen
    # è‚²å„¿ orange
    # å†™ä½œ lightpink
    # å•†åŠ¡ cyan
    # ç”Ÿæ´»åˆ†äº« lavender
    # ç»˜æœ¬ tomato
    # æ¯å©´ lightsalmon
    # å¥½ç‰©åˆ†äº« darkseagreen
    # åšä¸» darkcyan
    # è´­ç‰© skyblue
    # äºŒèƒè‚²å„¿ pink
    # è‚²å©´ wheat 
    # ç§‘å­¦è‚²å„¿ lightsteelblue
    # åª’ä½“ coral
    # æ•™è‚² sandybrown
    # äº²å­æ²Ÿé€š tab:green
    # å¥åº· tab:orange
    # å¾·å›½å“ç‰Œ tab:blue
    # åœ°çƒæ¢ç´¢ tab:cyan
    #['ç¾é£Ÿ', 'ç”Ÿæ´»', 'æ—…è¡Œ', 'æ‘„å½±', 'è‚²å„¿', 'å†™ä½œ', 'å•†åŠ¡', 'ç”Ÿæ´»åˆ†äº«', 'ç»˜æœ¬', 'æ¯å©´']
    #['ç”Ÿæ´»åˆ†äº«', 'è‚²å„¿', 'æ‘„å½±', 'ç¾é£Ÿ', 'å¥½ç‰©åˆ†äº«', 'åšä¸»', 'è´­ç‰©', 'äºŒèƒè‚²å„¿', 'è‚²å©´', 'ç§‘å­¦è‚²å„¿']
    #['è‚²å„¿', 'ç”Ÿæ´»åˆ†äº«', 'æ‘„å½±', 'åª’ä½“', 'æ•™è‚²', 'äº²å­æ²Ÿé€š', 'å¥åº·', 'å¾·å›½å“ç‰Œ', 'æ—…æ¸¸', 'åœ°çƒæ¢ç´¢']
    colors_a = ['gold', 'lightcoral', 'lightskyblue', 'lightgreen', 'orange', 'lightpink', 'cyan', 'lavender', 'lightsalmon', 'lightblue']
    colors_b = ['lavender', 'orange', 'lightgreen', 'gold', 'darkseagreen', 'darkcyan', 'skyblue', 'pink', 'wheat', 'lightsteelblue']
    colors_c = ['orange', 'lavender', 'lightgreen', 'coral', 'sandybrown', 'tab:green', 'tab:orange', 'tab:blue', 'lightskyblue', 'tab:cyan']
    # çªå‡ºæ˜¾ç¤ºæŸä¸ªç±»åˆ«ï¼Œå¯é€‰
    explode = (0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0)
    
    plt.rcParams['font.size'] = 12
    fig, ax = plt.subplots(figsize=(10, 10))
    # ç»˜åˆ¶é¥¼å›¾
    ax.pie(sizes, explode=explode, labels=labels, colors=colors_a, autopct='%1.1f%%', shadow=True, startangle=140, radius=2)
    # è®¾ç½®é¥¼å›¾çš„æ ‡é¢˜
    # plt.title("          é¢†åŸŸåˆ†å¸ƒ         ")
    # æ˜¾ç¤ºå›¾ä¾‹
    ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1))
    plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)
    # æ˜¾ç¤ºé¥¼å›¾
    plt.axis('equal')  # ä¿è¯é¥¼å›¾æ˜¯åœ†å½¢è€Œä¸æ˜¯æ¤­åœ†å½¢
    plt.tight_layout()
    plt.savefig('pie_chart_a.pdf', dpi=500)
    plt.show()


def plot_pr(x, y, labels):

    # ç”»å‡ºæ›²çº¿
    plt.figure(figsize=(8, 6))
    print(len(y))
    print(y)

    plt.plot(x, y[0], label=labels[0])
    plt.plot(x, y[1], label=labels[1])
    plt.plot(x, y[2], label=labels[2])
    plt.plot(x, y[3], label=labels[3])
    plt.plot(x, y[4], label=labels[4])
    plt.plot(x, y[5], label=labels[5])

    # æ·»åŠ å›¾ä¾‹
    plt.legend()

    # æ·»åŠ æ ‡é¢˜å’Œåæ ‡è½´æ ‡ç­¾
    plt.title('Simulation Scale Comparison')
    plt.xlabel('sample-k')
    plt.ylabel('metrics')

    # æ˜¾ç¤ºå›¾å½¢
    plt.show()

    


if __name__ == "__main__":
    gt_ids = PRODUCT_DETAIL[product]["gt_ids"]
    static_profile = load_static_profile()
    print(len(static_profile))
    seed_set = load_seeds(5, static_profile)
    # print(seed_set)
    print(len(seed_set))
    dynamic_profile = load_dynamic_profile()
    interaction_graph = load_interaction_graph()
    feature_dict = load_features()
    gt_names = [static_profile[_id]["user_name"] for _id in gt_ids]

    # step1
    # sample_user(static_profile, dynamic_profile, seed_set)

    # # step2
    # influencer_pre_selection(gt_ids, static_profile, feature_dict)

    # # step3
    # follower_profile_reasoning(static_profile, "sample")
    # follower_profile_reasoning(static_profile, "model")

    # step4
    follower_behavior_prediction("model", "prompt4behavior_stepbystep")
    # follower_behavior_prediction("model", "prompt4behavior_wo_profile")
    # follower_behavior_prediction("model", "prompt4behavior_wo_cot")


    # step5
    # eval for main method
    top_k = 13
    sample_k = 20
    whole_users, selection_names, predicted_names = influencer_ranking(static_profile, dynamic_profile, "model", "prompt4behavior_stepbystep", top_k, sample_k)
    # print(gt_names)
    # print(selection_names)
    # print(predicted_names)
    print("Main Method: ")
    overall_evaluation(gt_names, predicted_names)
    
    print("Pre-Selection: ")
    overall_evaluation(gt_names, selection_names[:10])

    whole_users, selection_names, predicted_names = influencer_ranking(static_profile, dynamic_profile, "model", "prompt4behavior_stepbystep", top_k, sample_k, "otherwise")
    # print(gt_names)
    # print(selection_names)
    # print(predicted_names)
    print("wo Simulation: ")
    overall_evaluation(gt_names, predicted_names)

    # # step5
    # eval for wo pre-selection
    whole_users, selection_names, predicted_names = influencer_ranking(static_profile, dynamic_profile, "sample", "prompt4behavior_stepbystep", top_k, sample_k)
    # step6
    # print(gt_names)
    # print(selection_names)
    # print(predicted_names)
    print("wo Pre-selection: ")
    overall_evaluation(gt_names, predicted_names)

    # step5
    # eval for wo profile
    whole_users, selection_names, predicted_names = influencer_ranking(static_profile, dynamic_profile, "model", "prompt4behavior_wo_profile", top_k, sample_k)
    # step6
    # print(gt_names)
    # print(selection_names)
    # print(predicted_names)
    print("wo Profile: ")
    overall_evaluation(gt_names, predicted_names)

    # # # step5
    # # eval for wo cot
    whole_users, selection_names, predicted_names = influencer_ranking(static_profile, dynamic_profile, "model", "prompt4behavior_wo_cot", top_k, sample_k)
    # step6
    # print(gt_names)
    # print(selection_names)
    # print(predicted_names)
    print("wo CoT: ")
    overall_evaluation(gt_names, predicted_names)

    # # step7 analysis
    # # print(whole_users)
    # # print(selection_names)
    # # print(predicted_names)
    # # display_domain_distribution(whole_users[:200])
    # # display_domain_distribution(selection_names[:20])
    # # display_domain_distribution(predicted_names[:10])

    # pr curve
    # write_f = open("pr.txt", "w+", encoding="utf-8")
    # top_k = 10
    # sample_k = 20
    # x = np.arange(1, 51)
    # y = [[]]*6
    # p_5 = []
    # p_10 = []
    # r_5 = []
    # r_10 = []
    # g_5 = []
    # g_10 = []
    # labels = ["P@5", "P@10", "R@5", "R@10", "G@5", "G@10"]
    # for top_k in range(1, 51):
    #     precision_5_all, precision_10_all, recall_5_all, recall_10_all, ndcg_5_all, ndcg_10_all = 0, 0, 0, 0, 0, 0
    #     for k in range(10):

    #         whole_users, selection_names, predicted_names = influencer_ranking(static_profile, dynamic_profile, "model", "prompt4behavior_stepbystep", top_k, sample_k)
    
    #         # step6
    #         # print(gt_names)
    #         # print(selection_names)
    #         # print(predicted_names)
    #         #print("Main Method: ")
    #         precision_5, precision_10, recall_5, recall_10, ndcg_5, ndcg_10 = overall_evaluation(gt_names, predicted_names)
    #         precision_5_all += precision_5
    #         precision_10_all += precision_10
    #         recall_5_all += recall_5
    #         recall_10_all += recall_10
    #         ndcg_5_all += ndcg_5
    #         ndcg_10_all += ndcg_10
    #     write_f.write("%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % (top_k, precision_5_all/10, precision_10_all/10, recall_5_all/10, recall_10_all/10, ndcg_5_all/10, ndcg_10_all/10))
    #     p_5.append(precision_5_all/10)
    #     p_10.append(precision_10_all/10)
    #     r_5.append(recall_5_all/10)
    #     r_10.append(recall_10_all/10)
    #     g_5.append(ndcg_5_all/10)
    #     g_10.append(ndcg_10_all/10)
    # write_f.close()
    # plot_pr(x, [p_5, p_10, r_5, r_10, g_5, g_10], labels)


